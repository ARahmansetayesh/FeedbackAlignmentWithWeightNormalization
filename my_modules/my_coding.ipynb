{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_coding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvkmVENu1Ex1"
      },
      "source": [
        "# Generating mutually exclusive n-hot  coding\n",
        "\n",
        "Suppose the number of categories is $C$  and number of output neurons is $m$  ($ n \\cdot C \\leq m$). For generating mutually exclusive $n$-hot code vectors of size $m$ for each category, we started from the first category to the last one and successively for each category $c \\in \\{0,1,\\cdots,C-1\\}$ we initialized its code vector with zero elements and then randomly selected $n$ out of $m-c \\cdot n$ elements that were not equal to $1$ in any of the $c$ previously coded category vectors and set them equal to $1$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prHcCYmRqX05"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rc14ya1XZzB"
      },
      "source": [
        "def Diff(li1, li2):\n",
        "    return list(set(li1) - set(li2)) + list(set(li2) - set(li1))\n",
        "\n",
        "# coding_layers should be a list of number of neurons in each layer \n",
        "# ones_in_layes should be a list of number of ones in each coding vector\n",
        " \n",
        "def get_n_hot_coding_map(coding_layers , ones_in_layes   , number_of_categories  ):\n",
        "\n",
        "  if(type(coding_layers) != list ):\n",
        "    raise Exception('coding_layers is not a list')\n",
        "  if(type(ones_in_layes) != list ):\n",
        "    raise Exception('ones_in_layes is not a list')\n",
        "\n",
        "\n",
        "  if(type(number_of_categories) != int ):\n",
        "    raise Exception('number_of_categories is not int')      \n",
        "\n",
        "  if(  len(coding_layers) != len(ones_in_layes)  ):\n",
        "    raise Exception('inputs len mismatch')  \n",
        "\n",
        "\n",
        "  coding = []\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  for i in range(len(coding_layers)):\n",
        "    if ( number_of_categories*(ones_in_layes[i]  ) > coding_layers[i]  ):\n",
        "      raise Exception('no a valide coding')\n",
        "\n",
        "\n",
        "\n",
        "    coding.append( np.zeros([number_of_categories,coding_layers[i]])     )\n",
        "\n",
        "    initial_indices_list = list(range(coding_layers[i]))\n",
        "    for j in range(number_of_categories):\n",
        "\n",
        "      indice = random.sample( initial_indices_list  , ones_in_layes[i] )\n",
        "      coding[i][j,indice] = 1\n",
        "      k=0\n",
        "      initial_indices_list = Diff(initial_indices_list, indice)\n",
        "        \n",
        "\n",
        "\n",
        "    coding[i] = torch.tensor(coding[i] , device=device, dtype=dtype, requires_grad=False )\n",
        "  \n",
        "  return coding\n",
        "\n",
        "# print(device)\n",
        "\n",
        "# coding  = get_n_hot_coding_map([100] , [ 10 ]       , 10 )    \n",
        "# # # print(coding)\n",
        "\n",
        "# m =  np.zeros( len(coding[0][0]) )\n",
        "\n",
        "# for i in range(len(coding[0])):\n",
        "#   m = m + np.array(coding[0][i])\n",
        "\n",
        "# print(m)\n",
        "\n",
        "# m = np.ones(len(coding[0][0]))\n",
        "# for i in range(len(coding[0])):\n",
        "#   m = m * np.array(coding[0][i])\n",
        "\n",
        "# print(m)\n",
        "\n",
        "# # print( np.array(coding[1][0]) + np.array(coding[1][1]) + np.array(coding[1][2]) )\n",
        "# # print( np.array(coding[1][0]) * np.array(coding[1][1]) * np.array(coding[1][2]) )\n",
        "# # print( np.array([0,2,3]) * np.array([3,2,5])  )\n",
        "# # i=0\n",
        "\n",
        "# # print(  torch.matmul(   coding[i]  , torch.transpose(coding[i],0, 1)      )   )\n",
        "\n",
        "\n",
        "\n",
        "# # i=1\n",
        "\n",
        "# # print(  torch.matmul(   coding[i]  , torch.transpose(coding[i],0, 1)      )   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96Ip80ACxMdy"
      },
      "source": [
        "# coding  : list of tensors with size : ( number_of_categories , coding_layers[i])   ,  coding_layers[i] is number of neurons in layer i\n",
        "# category : 1:can be (Batch size , 1)  2:can be (Batch size  ) \n",
        "\n",
        "\n",
        "def code_category(coding , category):\n",
        "  if(type(coding) != list ):\n",
        "    raise Exception('coding is not a list')\n",
        "\n",
        "  if(not torch.is_tensor(category) ):  \n",
        "    raise Exception('category is not a torch tensor')\n",
        "\n",
        "  coded = []\n",
        "  \n",
        "  if (len(category.shape)  == 1  or  (len(category.shape)  == 2  and  (category.shape[1])  == 1)):\n",
        "\n",
        "    category1 = category.view(-1).to(torch.int64 )\n",
        "    for i in range( len(coding) ):\n",
        "      coded.append(coding[i][  category1   , :])\n",
        "    \n",
        "    \n",
        "  #if its one hot code\n",
        "  else :\n",
        "    raise Exception('category size mismach')\n",
        "\n",
        "  return coded \n",
        "\n",
        "\n",
        "\n",
        "    # for i in range(len(coding)):\n",
        "    #   output.append()\n",
        "\n",
        "# a=np.array(  [2,1,1,1,1,1,1])\n",
        "# # print(a.shape)\n",
        "# category = torch.tensor(a).view([-1,1])\n",
        "\n",
        "# category = torch.tensor([ [0,0,1] ,  [1,0,0]  ,  [1,0,0]  ,  [1,0,1] ] , dtype=dtype )\n",
        "# # category = torch.tensor(a)\n",
        "# # category = a\n",
        "# # print(category.shape)\n",
        "# print(category)\n",
        "# # print(category.shape)\n",
        "\n",
        "\n",
        "# code = get_distributed_coding_map([5,3] , [ 2,1]    , [1,0]   , 3 ) \n",
        "# print(code)\n",
        "\n",
        "# code_category(code , category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJDZb86nP9G3"
      },
      "source": [
        "# coding  : list of tensors with size : ( number_of_categories , coding_layers[i])   ,  coding_layers[i] is number of neurons in layer i\n",
        "# activity  : list of activity of layers with size : ( batch_size , coding_layers[i])\n",
        "\n",
        "# return  : tesor of size : ( batch_size , top )\n",
        "\n",
        "def decode_category(coding , activity , top=1 , coef=None):\n",
        "  if(type(coding) != list ):\n",
        "    raise Exception('coding is not a list')\n",
        "\n",
        "  if(type(activity) != list ):\n",
        "    raise Exception('activity is not a list')\n",
        "\n",
        "  result =  torch.zeros( [  activity[0].shape[0] , coding[0].shape[0] ]  , device = device , dtype=dtype, requires_grad=False )\n",
        "\n",
        "\n",
        "  for i in range(len(coding)):\n",
        "    if (coef==None):\n",
        "      result = result + torch.matmul( activity[i]  , torch.transpose( coding[i] , 0 , 1 ) ) \n",
        "\n",
        "    else:\n",
        "      result = result + coef[i] * torch.matmul( activity[i]  , torch.transpose( coding[i] , 0 , 1 ) ) \n",
        "\n",
        "  result2 =  torch.zeros( [activity[0].shape[0] , top ] , device = device , dtype=dtype, requires_grad=False )\n",
        "\n",
        "\n",
        "  for i in range(top): \n",
        "    a,indece = torch.max(result ,dim=1)\n",
        "\n",
        "    result2[np.arange(activity[0].shape[0])  , i ] = indece.view([-1]).to(dtype)\n",
        "    result[np.arange(result.shape[0]) ,indece.view([-1]) ] = -1\n",
        "  return result2\n",
        "  \n",
        "\n",
        "\n",
        "# code = get_distributed_coding_map([5,3] , [ 2,1]    , [1,0]   , 3 ) \n",
        "\n",
        "# print(code[0])\n",
        "# print(code[1])\n",
        "\n",
        "# code1 =  torch.tensor( [[1,0,0,1,0] , [0,1,0,0,0] , [0,0,1,0,0]  ] )\n",
        "# code2 =  torch.tensor( [[1,0,0] , [0,1,0] , [0,0,1]  ] )\n",
        "\n",
        "\n",
        "\n",
        "# activity1 = torch.tensor( [[1,1,1,1,0] , [0,1,0,1,0] , [0,0,0,1,0] , [0,0,1,0,0] , [0,0,1,0,0] , [0,1,0,1,0]] )\n",
        "\n",
        "# activity2 = torch.tensor( [[1,0,1] , [0,0,0] , [0,1,0] , [0,0,1] , [0,1,0] , [0,1,0]] )\n",
        "\n",
        "# res = decode_category([code1,code2] , [activity1,activity2] ,top=2 , coef = [0.1 , 0.9]  )\n",
        "\n",
        "# print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_1bN0G1fE16"
      },
      "source": [
        "\n",
        "# true_labels size : (batch size , 1)  or (batch size)\n",
        "def get_accuracy( true_labels , coding  , activity , top=1 , coef=None ):\n",
        "\n",
        "  if(type(activity) != list ):\n",
        "    raise Exception('activity is not a list')\n",
        "\n",
        "  if(true_labels.shape[0] != activity[0].shape[0]  or  len(true_labels.shape) >  1):\n",
        "    raise Exception('true_labels shape mismatch')\n",
        "\n",
        "  if(not torch.is_tensor(true_labels) ):  \n",
        "    raise Exception('true_labels is not a torch tensor')\n",
        "\n",
        "  true_labels = true_labels.view([-1,1])\n",
        "\n",
        "\n",
        "  predicted = decode_category(coding , activity , top=top , coef=coef)\n",
        "\n",
        "  res = torch.sum(torch.clamp( torch.sum(predicted == true_labels , dim=1)  , 0 ,1 )).to(dtype)/true_labels.shape[0]\n",
        "  return res.item()\n",
        "\n",
        "\n",
        "\n",
        "# code1 =  torch.tensor( [[1,0,0,1,0] , [0,1,0,0,0] , [0,0,1,0,0]  ] )\n",
        "# code2 =  torch.tensor( [[1,0,0] , [0,1,0] , [0,0,1]  ] )\n",
        "\n",
        "\n",
        "\n",
        "# activity1 = torch.tensor( [[1,1,1,1,0] , [0,1,0,1,0] , [0,0,0,1,0] , [0,0,1,0,0] , [0,0,1,0,0] , [0,1,0,1,0]] )\n",
        "\n",
        "# activity2 = torch.tensor( [[1,0,1] , [0,0,0] , [0,1,0] , [0,0,1] , [0,1,0] , [0,1,0]] )\n",
        "\n",
        "# true_labels = torch.tensor([1,1,0,2,1,2])\n",
        "# get_accuracy( true_labels  , [code1,code2] , [activity1,activity2] ,top=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IST0HnxhzT0R"
      },
      "source": [
        "# x list of size (batch , coding[0].shape[1]  + coding[1].shape[1]  + ... )\n",
        "\n",
        "def seprate(coding , x):\n",
        "  if(not torch.is_tensor(x) ):  \n",
        "    raise Exception('x is not a torch tensor')\n",
        "\n",
        "  if(type(coding) != list ):\n",
        "    raise Exception('coding is not a list')\n",
        "\n",
        "  mlist = []\n",
        "  form_ = 0\n",
        "  til=0\n",
        "  for i in range(len(coding)):\n",
        "    til = til + coding[i].shape[1]\n",
        "    mlist.append(x[: , form_ : til])\n",
        "    form_ = form_ + coding[i].shape[1]\n",
        "    if(til > x.shape[1]):  \n",
        "      raise Exception('x size mismatch')\n",
        "\n",
        "\n",
        "  if(til != x.shape[1]):  \n",
        "    raise Exception('x size mismatch')\n",
        "\n",
        "  return mlist\n",
        "\n",
        "\n",
        "# coding  = get_distributed_coding_map([3,4] , [ 1 ,1 ]    , [2,1]   , 3 )    \n",
        "\n",
        "# x = torch.rand([5,7])\n",
        "\n",
        "# y =seprate(coding , x)\n",
        "# print(x)\n",
        "# print(y)\n",
        "\n",
        "# x = torch.tensor([[1,2,3.3],[5.4,1,0.2]])\n",
        "# print(x)\n",
        "# a,b = torch.max(x ,dim=1)\n",
        "\n",
        "# x[np.arange(x.shape[0]) , b ] = -1\n",
        "# print(b)\n",
        "\n",
        "# print(x)\n",
        "\n",
        "# a,b = torch.max(x ,dim=1)\n",
        "\n",
        "# x[np.arange(x.shape[0]) , b ] = -1\n",
        "# print(b)\n",
        "\n",
        "# print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgs2M-bvTy4e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}